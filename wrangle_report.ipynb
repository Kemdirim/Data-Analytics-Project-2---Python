{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA WRANGLING REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a brief report documenting  my wrangling (gathering, assessing and cleaning) efforts on the data from the Twitter user **@dog_rates**, also known as **WeRateDogs** which is a Twitter account that rates people's dogs with a humorous comment about the dog. The steps below were taken:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this phase, I gathered data from three different sources, each requiring a different method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first was **The WeRateDogs Twitter archive data** (twitter-archive-enhanced.csv) which I downloaded manually from the Udacity classroom. I uploaded it and read the data into a pandas Dataframe, **archived_df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second data **The tweet image predictions** (image-predictions.tsv) was hosted on Udacity's servers and I downloaded it programmatically using the **Requests** library and the URL to the file provided in the classroom. I then read it into a pandas Dataframe, **image_df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third data was sourced from the **Twitter API**. Using the tweet IDs in the WeRateDogs Twitter archive, I queried the Twitter API for each tweet's JSON data using Python's Tweepy library. The JSON data for each tweet was written line by line and stored in a text file named **\"tweet_json.txt\"**. I then read the 'tweet_json.txt' file and looped through each line loading the json data with the json library and extracted each tweet's **tweet ID, retweet count, favorite count, and followers count** into a dictionary. I appended the dictionary into an empty list. To conclude the process, I converted this list of dictionaries into a pandas Dataframe, **api_df**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assessed the three dataframes/tables above both visually and programmatically and identified the  following quality and tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### archived_df table\n",
    "1. Contains retweets, need only original tweets with images\n",
    "\n",
    "2. Drop irrelevant columns\n",
    "\n",
    "3. Erroneous datatypes (tweet_id, timestamp, and source columns)\n",
    "\n",
    "4. Short links attached to text in text column\n",
    "\n",
    "5. Source column written in HTML format (content contained in HTML link tag) \n",
    "\n",
    "##### image_df table\n",
    "6. Erroneous datatype (tweet_id column)\n",
    "\n",
    "7. Missing image records (2075 instead of 2356)\n",
    "\n",
    "##### api_df table\n",
    "8. Missing records (2354 instead of 2356)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. doggo, floofer, pupper, and puppo columns in archived_df table should be combined into one (1) variable. \n",
    "\n",
    "2. image_df table and api_df table should be merged (combined) with the archived_df table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality and tidiness issues identified in the assessing phase above were cleaned as seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness Issues Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concatenated doggo, floofer, pupper, and puppo columns into one \"dog_stage\" column.\n",
    "- Merged the image_df table and api_df table to archived_df table, with a left join, joining on tweet_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Issues Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kept only original tweets by selecting records with null retweet information (retweeted_status_id).\n",
    "- converted tweet_id from integer to string datatypes. Converted timestamp to datetime data type. Converted source to categorical data type.\n",
    "- Dropped all columns not needed for our analysis (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls).\n",
    "- Dropped all Nan records in archive_df to cater for missing records in both image_df and api_df tables.\n",
    "- Used regex to split the text column and return content without the links.\n",
    "- Used regex pattern matching to extract the text in the HTML tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the cleaned data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering the needed data, assessing possible issues and cleaning these identified issues, I saved the cleaned dataset as a csv file \"twitter_archive_master.csv\" and the proceeded to perform an analysis on it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
